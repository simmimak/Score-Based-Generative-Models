{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M4ePuNDjney",
        "outputId": "10c915c8-d761-45da-d0ae-a3aa290bca48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.1.post0-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Collecting lightning-utilities>=0.7.0\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.4.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.1.post0 torchmetrics-0.11.4 yarl-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch-lightning wandb"
      ],
      "metadata": {
        "id": "gLMkg8zNV_tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f71ef73-be56-4560-9c71-42743e02a9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3Mcw5ACfV6PB",
        "outputId": "e38fa09c-9abd-451a-b6a3-cf578303bbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcLq5IDNjmk3"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Oeix-gkUTA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "def get_train_data(conf):\n",
        "    if conf.dataset.name == 'mnist':\n",
        "\n",
        "        transform = T.Compose(\n",
        "            [\n",
        "                #T.RandomHorizontalFlip(),\n",
        "                T.ToTensor(),\n",
        "                #T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
        "            ]\n",
        "        )\n",
        "        transform_test = T.Compose(\n",
        "            [\n",
        "                T.ToTensor(),\n",
        "                #T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        train_set = torchvision.datasets.MNIST(conf.dataset.path,\n",
        "                                                 train=True,\n",
        "                                                 transform=transform,\n",
        "                                                 download=True)\n",
        "        valid_set = torchvision.datasets.MNIST(conf.dataset.path,\n",
        "                                                  train=True,\n",
        "                                                  transform=transform_test,\n",
        "                                                  download=True)\n",
        "\n",
        "        num_train  = len(train_set)\n",
        "        indices    = torch.randperm(num_train).tolist()\n",
        "        valid_size = int(np.floor(0.05 * num_train))\n",
        "\n",
        "        train_idx, valid_idx = indices[valid_size:], indices[:valid_size]\n",
        "\n",
        "        train_set = Subset(train_set, train_idx)\n",
        "        valid_set = Subset(valid_set, valid_idx)\n",
        "\n",
        "\n",
        "        test_set = torchvision.datasets.MNIST(conf.dataset.path,\n",
        "                                                 train=False,\n",
        "                                                 transform=transform_test,\n",
        "                                                 download=True)\n",
        "   \n",
        "    else:\n",
        "        raise FileNotFoundError\n",
        "\n",
        "    return train_set, valid_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfXk9ydsj1nN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy import integrate\n",
        "\n",
        "class VariancePreservingSDE(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0, t_epsilon=0.001):\n",
        "        super().__init__()\n",
        "        self.beta_min = beta_min\n",
        "        self.beta_max = beta_max\n",
        "        self.T = T\n",
        "        self.t_epsilon = t_epsilon\n",
        "\n",
        "    def beta(self, t):\n",
        "        return self.beta_min + (self.beta_max-self.beta_min)*t\n",
        "\n",
        "    def mean_weight(self, t):\n",
        "        return torch.exp(-0.25 * t**2 * (self.beta_max-self.beta_min) - 0.5 * t * self.beta_min)\n",
        "\n",
        "    def var(self, t):\n",
        "        return 1. - torch.exp(-0.5 * t**2 * (self.beta_max-self.beta_min) - t * self.beta_min)\n",
        "    \n",
        "    def marginal_prob_std(self, t):\n",
        "       return self.var(t) ** 0.5 \n",
        "       \n",
        "    def f(self, t, y):\n",
        "        return - 0.5 * self.beta(t) * y\n",
        "\n",
        "    def g(self, t, y):\n",
        "        beta_t = self.beta(t)\n",
        "        return beta_t**0.5\n",
        "\n",
        "    def sample(self, t, y0, return_noise=False):\n",
        "      \n",
        "        mu = self.mean_weight(t) * y0\n",
        "        std = self.var(t) ** 0.5\n",
        "        epsilon = torch.randn_like(y0)\n",
        "        yt = epsilon * std + mu\n",
        "        if not return_noise:\n",
        "            return yt\n",
        "        else:\n",
        "            return yt, epsilon, std, self.g(t, yt)\n",
        "\n",
        "\n",
        "error_tolerance = 1e-5\n",
        "def ode_sampler(score_model,\n",
        "                batch_size=64, \n",
        "                atol=error_tolerance, \n",
        "                rtol=error_tolerance, \n",
        "                device='cuda', \n",
        "                z=None,\n",
        "                eps=1e-3):\n",
        "    \n",
        "    T1 = torch.nn.Parameter(torch.FloatTensor([1.0]), requires_grad=False)\n",
        "        \n",
        "    sde = VariancePreservingSDE(beta_min=0.1, beta_max=20.0, T=T1)\n",
        "\n",
        "    t = torch.ones(batch_size, device=device)\n",
        "\n",
        "    if z is None:\n",
        "        init_x = torch.randn(batch_size, 1, 28, 28, device=device) \\\n",
        "        * sde.marginal_prob_std(t)[:, None, None, None]\n",
        "    else:\n",
        "        init_x = z\n",
        "        \n",
        "    shape = init_x.shape\n",
        "\n",
        "    def score_eval_wrapper(sample, time_steps):\n",
        "        sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
        "        time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))   \n",
        "\n",
        "        with torch.no_grad():    \n",
        "            score = score_model(sample, time_steps)\n",
        "            return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
        "    \n",
        "    def ode_func(t, x):        \n",
        "        time_steps = np.ones((shape[0],)) * t   \n",
        "\n",
        "        g = sde.g(torch.tensor(t),np.ones((shape[0],))).cpu().numpy()\n",
        "\n",
        "        return  -0.5 * (g**2) * score_eval_wrapper(x, time_steps)\n",
        "\n",
        "\n",
        "    res = integrate.solve_ivp(ode_func, (1., eps), init_x.reshape(-1).cpu().numpy(), rtol=rtol, atol=atol, method='RK45')  \n",
        "    print(f\"Number of function evaluations: {res.nfev}\")\n",
        "    x = torch.tensor(res.y[:, -1], device=device).reshape(shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def prior_likelihood(z, sigma):\n",
        "  shape = z.shape\n",
        "  N = np.prod(shape[1:])\n",
        "  return -N / 2. * torch.log(2*np.pi*sigma**2) - torch.sum(z**2, dim=(1,2,3)) / (2 * sigma**2)\n",
        "\n",
        "def ode_likelihood(x, \n",
        "                   score_model,\n",
        "                   batch_size=64, \n",
        "                   eps=1e-5):\n",
        "    \n",
        "    epsilon = torch.randn_like(x)\n",
        "    device='cuda'\n",
        "    T1 = torch.nn.Parameter(torch.FloatTensor([1.0]), requires_grad=False)\n",
        "        \n",
        "    sde = VariancePreservingSDE(beta_min=0.1, beta_max=20.0, T=T1)\n",
        "  \n",
        "    def divergence_eval(sample, time_steps, epsilon):      \n",
        "      \n",
        "        with torch.enable_grad():\n",
        "            sample.requires_grad_(True)\n",
        "            score_e = torch.sum(score_model(sample, time_steps) * epsilon)\n",
        "            #print(\"bkjs3\")\n",
        "            grad_score_e = torch.autograd.grad(score_e, sample)[0]\n",
        "            #print(\"bkjs3\")\n",
        "        return torch.sum(grad_score_e * epsilon, dim=(1, 2, 3))    \n",
        "    \n",
        "    shape = x.shape\n",
        "\n",
        "    def score_eval_wrapper(sample, time_steps):\n",
        "        sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
        "        time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], ))    \n",
        "        with torch.no_grad():    \n",
        "            score = score_model(sample, time_steps)\n",
        "        return score.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
        "    \n",
        "    def divergence_eval_wrapper(sample, time_steps):\n",
        "        with torch.no_grad():\n",
        "            sample = torch.tensor(sample, device=device, dtype=torch.float32).reshape(shape)\n",
        "            #print(\"bkjs1\")\n",
        "            time_steps = torch.tensor(time_steps, device=device, dtype=torch.float32).reshape((sample.shape[0], )) \n",
        "            #print(\"bkjs2\")\n",
        "            div = divergence_eval(sample, time_steps, epsilon)\n",
        "            #print(\"bkjs4\")\n",
        "            return div.cpu().numpy().reshape((-1,)).astype(np.float64)\n",
        "        \n",
        "    def ode_func(t, x):\n",
        "        time_steps = np.ones((shape[0],)) * t    \n",
        "        sample = x[:-shape[0]]\n",
        "        #print(sample.shape)\n",
        "        logp = x[-shape[0]:]\n",
        "        g = sde.g(torch.tensor(t), torch.tensor(sample)).cpu().numpy()\n",
        "        sample_grad = -0.5 * g**2 * score_eval_wrapper(sample, time_steps)\n",
        "        #print(sample.shape, time_steps.shape)\n",
        "        #print(divergence_eval_wrapper(sample, time_steps).shape , g.shape)\n",
        "        logp_grad = -0.5 * g**2 * divergence_eval_wrapper(sample, time_steps)\n",
        "        #print(\"bkjs5\")\n",
        "        return np.concatenate([sample_grad, logp_grad], axis=0)\n",
        "\n",
        "\n",
        "    init = np.concatenate([x.cpu().numpy().reshape((-1,)), np.zeros((shape[0],))], axis=0)\n",
        "    res = integrate.solve_ivp(ode_func, (eps, 1.), init, rtol=1e-5, atol=1e-5, method='RK45')  \n",
        "    zp = torch.tensor(res.y[:, -1], device=device)\n",
        "    z = zp[:-shape[0]].reshape(shape)\n",
        "    delta_logp = zp[-shape[0]:].reshape(shape[0])\n",
        "    sigma_max = sde.marginal_prob_std( torch.tensor(1., device=device))\n",
        "    prior_logp = prior_likelihood(z, sigma_max)\n",
        "    bpd = -(prior_logp + delta_logp) / np.log(2)\n",
        "    N = np.prod(shape[1:])\n",
        "    bpd = bpd / N + 8.\n",
        "    return z, bpd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeKMKy1bnvAy"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.init import _calculate_fan_in_and_fan_out\n",
        "\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(x) * x\n",
        "\n",
        "\n",
        "def group_norm(out_ch):\n",
        "    return nn.GroupNorm(num_groups=32, num_channels=out_ch, eps=1e-6, affine=True)\n",
        "\n",
        "\n",
        "def upsample(in_ch, with_conv):\n",
        "    up = nn.Sequential()\n",
        "    up.add_module('up_nn', nn.Upsample(scale_factor=2, mode='nearest'))\n",
        "    if with_conv:\n",
        "        up.add_module('up_conv', conv2d(in_ch, in_ch, kernel_size=(3, 3), stride=1))\n",
        "    return up\n",
        "\n",
        "\n",
        "def downsample(in_ch, with_conv):\n",
        "    if with_conv:\n",
        "        down = conv2d(in_ch, in_ch, kernel_size=(3, 3), stride=2)\n",
        "    else:\n",
        "        down = nn.AvgPool2d(2, 2)\n",
        "    return down\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_ch, temb_ch, out_ch=None, conv_shortcut=False, dropout=0., normalize=group_norm, act=Swish()):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.temb_ch = temb_ch\n",
        "        self.out_ch = out_ch if out_ch is not None else in_ch\n",
        "        self.conv_shortcut = conv_shortcut\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "        self.temb_proj = dense(temb_ch, out_ch)\n",
        "        self.norm1 = normalize(in_ch) if normalize is not None else nn.Identity()\n",
        "        self.conv1 = conv2d(in_ch, out_ch)\n",
        "        self.norm2 = normalize(out_ch) if normalize is not None else nn.Identity()\n",
        "        self.dropout = nn.Dropout2d(p=dropout) if dropout > 0. else nn.Identity()\n",
        "        self.conv2 = conv2d(out_ch, out_ch, init_scale=0.)\n",
        "        if in_ch != out_ch:\n",
        "            if conv_shortcut:\n",
        "                self.shortcut = conv2d(in_ch, out_ch)\n",
        "            else:\n",
        "                self.shortcut = conv2d(in_ch, out_ch, kernel_size=(1, 1), padding=0)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x, temb):\n",
        "        # forward conv1\n",
        "        h = x\n",
        "        h = self.act(self.norm1(h))\n",
        "        h = self.conv1(h)\n",
        "\n",
        "        # add in timestep embedding\n",
        "        h = h + self.temb_proj(self.act(temb))[:, :, None, None]\n",
        "\n",
        "        # forward conv2\n",
        "        h = self.act(self.norm2(h))\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        # shortcut\n",
        "        x = self.shortcut(x)\n",
        "\n",
        "        # combine and return\n",
        "        assert x.shape == h.shape\n",
        "        return x + h\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, normalize=group_norm):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.attn_q = conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.attn_k = conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.attn_v = conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.proj_out = conv2d(in_channels, in_channels, kernel_size=1, stride=1, padding=0, init_scale=0.)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        if normalize is not None:\n",
        "            self.norm = normalize(in_channels)\n",
        "        else:\n",
        "            self.norm = nn.Identity()\n",
        "\n",
        "    # noinspection PyUnusedLocal\n",
        "    def forward(self, x, temp=None):\n",
        "        \"\"\" t is not used \"\"\"\n",
        "        _, C, H, W = x.size()\n",
        "\n",
        "        h = self.norm(x)\n",
        "        q = self.attn_q(h).view(-1, C, H * W)\n",
        "        k = self.attn_k(h).view(-1, C, H * W)\n",
        "        v = self.attn_v(h).view(-1, C, H * W)\n",
        "\n",
        "        attn = torch.bmm(q.permute(0, 2, 1), k) * (int(C) ** (-0.5))\n",
        "        attn = self.softmax(attn)\n",
        "\n",
        "        h = torch.bmm(v, attn.permute(0, 2, 1))\n",
        "        h = h.view(-1, C, H, W)\n",
        "        h = self.proj_out(h)\n",
        "\n",
        "        assert h.shape == x.shape\n",
        "        return x + h\n",
        "\n",
        "\n",
        "def _calculate_correct_fan(tensor, mode):\n",
        "    \n",
        "    mode = mode.lower()\n",
        "    valid_modes = ['fan_in', 'fan_out', 'fan_avg']\n",
        "    if mode not in valid_modes:\n",
        "        raise ValueError(\"Mode {} not supported, please use one of {}\".format(mode, valid_modes))\n",
        "\n",
        "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
        "    return fan_in if mode == 'fan_in' else fan_out\n",
        "\n",
        "\n",
        "def kaiming_uniform_(tensor, gain=1., mode='fan_in'):\n",
        "   \n",
        "    fan = _calculate_correct_fan(tensor, mode)\n",
        "    # gain = calculate_gain(nonlinearity, a)\n",
        "    var = gain / max(1., fan)\n",
        "    bound = math.sqrt(3.0 * var)  # Calculate uniform bounds from standard deviation\n",
        "    with torch.no_grad():\n",
        "        return tensor.uniform_(-bound, bound)\n",
        "\n",
        "\n",
        "def variance_scaling_init_(tensor, scale):\n",
        "    return kaiming_uniform_(tensor, gain=1e-10 if scale == 0 else scale, mode='fan_avg')\n",
        "\n",
        "\n",
        "def dense(in_channels, out_channels, init_scale=1.):\n",
        "    lin = nn.Linear(in_channels, out_channels)\n",
        "    variance_scaling_init_(lin.weight, scale=init_scale)\n",
        "    nn.init.zeros_(lin.bias)\n",
        "    return lin\n",
        "\n",
        "\n",
        "def conv2d(in_planes, out_planes, kernel_size=(3, 3), stride=1, dilation=1, padding=1, bias=True, padding_mode='zeros',\n",
        "           init_scale=1.):\n",
        "    conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation,\n",
        "                     bias=bias, padding_mode=padding_mode)\n",
        "    variance_scaling_init_(conv.weight, scale=init_scale)\n",
        "    if bias:\n",
        "        nn.init.zeros_(conv.bias)\n",
        "    return conv\n",
        "\n",
        "\n",
        "def get_sinusoidal_positional_embedding(timesteps: torch.LongTensor, embedding_dim: int):\n",
        "\n",
        "    assert len(timesteps.size()) == 1\n",
        "    timesteps = timesteps.to(torch.get_default_dtype())\n",
        "    device = timesteps.device\n",
        "\n",
        "    half_dim = embedding_dim // 2\n",
        "    emb = math.log(10000) / (half_dim - 1)\n",
        "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float, device=device) * -emb)\n",
        "    emb = timesteps[:, None] * emb[None, :]\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)  # bsz x embd\n",
        "    if embedding_dim % 2 == 1:  # zero pad\n",
        "        emb = F.pad(emb, (0, 1), \"constant\", 0)\n",
        "    assert list(emb.size()) == [timesteps.size(0), embedding_dim]\n",
        "    return emb\n",
        "\n",
        "\n",
        "class TimestepEmbedding(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, act=Swish()):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            dense(embedding_dim, hidden_dim),\n",
        "            act,\n",
        "            dense(hidden_dim, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, temp):\n",
        "        temb = get_sinusoidal_positional_embedding(temp, self.embedding_dim)\n",
        "        temb = self.main(temb)\n",
        "        return temb\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_channels,\n",
        "                 input_height,\n",
        "                 ch,\n",
        "                 output_channels=None,\n",
        "                 ch_mult=(1, 2, 4, 8),\n",
        "                 num_res_blocks=2,\n",
        "                 attn_resolutions=(16,),\n",
        "                 dropout=0.,\n",
        "                 resamp_with_conv=True,\n",
        "                 act=Swish(),\n",
        "                 normalize=group_norm,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "        self.input_height = input_height\n",
        "        self.ch = ch\n",
        "        self.output_channels = output_channels = input_channels if output_channels is None else output_channels\n",
        "        self.ch_mult = ch_mult\n",
        "        self.num_res_blocks = num_res_blocks\n",
        "        self.attn_resolutions = attn_resolutions\n",
        "        self.dropout = dropout\n",
        "        self.resamp_with_conv = resamp_with_conv\n",
        "        self.act = act\n",
        "        self.normalize = normalize\n",
        "\n",
        "        # init\n",
        "        self.num_resolutions = num_resolutions = len(ch_mult)\n",
        "        in_ht = input_height\n",
        "        in_ch = input_channels\n",
        "        temb_ch = ch * 4\n",
        "\n",
        "        assert in_ht % 2 ** (num_resolutions - 1) == 0, \"input_height doesn't satisfy the condition\"\n",
        "\n",
        "        # Timestep embedding\n",
        "        self.temb_net = TimestepEmbedding(\n",
        "            embedding_dim=ch,\n",
        "            hidden_dim=temb_ch,\n",
        "            output_dim=temb_ch,\n",
        "            act=act,\n",
        "        )\n",
        "\n",
        "        # Downsampling\n",
        "        self.begin_conv = conv2d(in_ch, ch)\n",
        "        unet_chs = [ch]\n",
        "        in_ht = in_ht\n",
        "        in_ch = ch\n",
        "        down_modules = []\n",
        "        for i_level in range(num_resolutions):\n",
        "            # Residual blocks for this resolution\n",
        "            \n",
        "            block_modules = {}\n",
        "            out_ch = ch * ch_mult[i_level]\n",
        "            for i_block in range(num_res_blocks):\n",
        "\n",
        "                block_modules['{}a_{}a_block'.format(i_level, i_block)] = \\\n",
        "                    ResidualBlock(\n",
        "                        in_ch=in_ch,\n",
        "                        temb_ch=temb_ch,\n",
        "                        out_ch=out_ch,\n",
        "                        dropout=dropout,\n",
        "                        act=act,\n",
        "                        normalize=normalize,\n",
        "                    )\n",
        "                if in_ht in attn_resolutions:\n",
        "                    block_modules['{}a_{}b_attn'.format(i_level, i_block)] = SelfAttention(out_ch, normalize=normalize)\n",
        "                unet_chs += [out_ch]\n",
        "                in_ch = out_ch\n",
        "            # Downsample\n",
        "            if i_level != num_resolutions - 1:\n",
        "                block_modules['{}b_downsample'.format(i_level)] = downsample(out_ch, with_conv=resamp_with_conv)\n",
        "                in_ht //= 2\n",
        "                unet_chs += [out_ch]\n",
        "            # convert list of modules to a module list, and append to a list\n",
        "            down_modules += [nn.ModuleDict(block_modules)]\n",
        "        # conver to a module list\n",
        "        self.down_modules = nn.ModuleList(down_modules)\n",
        "\n",
        "        # Middle\n",
        "        mid_modules = []\n",
        "        mid_modules += [\n",
        "            ResidualBlock(in_ch, temb_ch=temb_ch, out_ch=in_ch, dropout=dropout, act=act, normalize=normalize)]\n",
        "        mid_modules += [SelfAttention(in_ch, normalize=normalize)]\n",
        "        mid_modules += [\n",
        "            ResidualBlock(in_ch, temb_ch=temb_ch, out_ch=in_ch, dropout=dropout, act=act, normalize=normalize)]\n",
        "        self.mid_modules = nn.ModuleList(mid_modules)\n",
        "\n",
        "        # Upsampling\n",
        "        up_modules = []\n",
        "        for i_level in reversed(range(num_resolutions)):\n",
        "            # Residual blocks for this resolution\n",
        "            block_modules = {}\n",
        "            out_ch = ch * ch_mult[i_level]\n",
        "            for i_block in range(num_res_blocks + 1):\n",
        "                block_modules['{}a_{}a_block'.format(i_level, i_block)] = \\\n",
        "                    ResidualBlock(\n",
        "                        in_ch=in_ch + unet_chs.pop(),\n",
        "                        temb_ch=temb_ch,\n",
        "                        out_ch=out_ch,\n",
        "                        dropout=dropout,\n",
        "                        act=act,\n",
        "                        normalize=normalize)\n",
        "                if in_ht in attn_resolutions:\n",
        "                    block_modules['{}a_{}b_attn'.format(i_level, i_block)] = SelfAttention(out_ch, normalize=normalize)\n",
        "                in_ch = out_ch\n",
        "            # Upsample\n",
        "            if i_level != 0:\n",
        "                block_modules['{}b_upsample'.format(i_level)] = upsample(out_ch, with_conv=resamp_with_conv)\n",
        "                in_ht *= 2\n",
        "            # convert list of modules to a module list, and append to a list\n",
        "            up_modules += [nn.ModuleDict(block_modules)]\n",
        "        # conver to a module list\n",
        "        self.up_modules = nn.ModuleList(up_modules)\n",
        "        assert not unet_chs\n",
        "\n",
        "        # End\n",
        "        self.end_conv = nn.Sequential(\n",
        "            normalize(in_ch),\n",
        "            self.act,\n",
        "            conv2d(in_ch, output_channels, init_scale=0.),\n",
        "        )\n",
        "\n",
        "    # noinspection PyMethodMayBeStatic\n",
        "    def _compute_cond_module(self, module, x, temp):\n",
        "        for m in module:\n",
        "            x = m(x, temp)\n",
        "        return x\n",
        "\n",
        "    # noinspection PyArgumentList,PyShadowingNames\n",
        "    def forward(self, x, temp):\n",
        "        # Init\n",
        "        B, C, H, W = x.size()\n",
        "\n",
        "        # Timestep embedding\n",
        "        temb = self.temb_net(temp)\n",
        "        assert list(temb.shape) == [B, self.ch * 4]\n",
        "\n",
        "        # Downsampling\n",
        "        hs = [self.begin_conv(x)]\n",
        "        for i_level in range(self.num_resolutions):\n",
        "            # Residual blocks for this resolution\n",
        "            block_modules = self.down_modules[i_level]\n",
        "            for i_block in range(self.num_res_blocks):\n",
        "                resnet_block = block_modules['{}a_{}a_block'.format(i_level, i_block)]\n",
        "                h = resnet_block(hs[-1], temb)\n",
        "                if h.size(2) in self.attn_resolutions:\n",
        "                    attn_block = block_modules['{}a_{}b_attn'.format(i_level, i_block)]\n",
        "                    h = attn_block(h, temb)\n",
        "                hs.append(h)\n",
        "            # Downsample\n",
        "            if i_level != self.num_resolutions - 1:\n",
        "                downsample = block_modules['{}b_downsample'.format(i_level)]\n",
        "                hs.append(downsample(hs[-1]))\n",
        "\n",
        "        # Middle\n",
        "        h = hs[-1]\n",
        "        h = self._compute_cond_module(self.mid_modules, h, temb)\n",
        "\n",
        "        # Upsampling\n",
        "        for i_idx, i_level in enumerate(reversed(range(self.num_resolutions))):\n",
        "            # Residual blocks for this resolution\n",
        "            block_modules = self.up_modules[i_idx]\n",
        "            for i_block in range(self.num_res_blocks + 1):\n",
        "                resnet_block = block_modules['{}a_{}a_block'.format(i_level, i_block)]\n",
        "                h = resnet_block(torch.cat([h, hs.pop()], axis=1), temb)\n",
        "                if h.size(2) in self.attn_resolutions:\n",
        "                    attn_block = block_modules['{}a_{}b_attn'.format(i_level, i_block)]\n",
        "                    h = attn_block(h, temb)\n",
        "            # Upsample\n",
        "            if i_level != 0:\n",
        "                upsample = block_modules['{}b_upsample'.format(i_level)]\n",
        "                h = upsample(h)\n",
        "        assert not hs\n",
        "\n",
        "        # End\n",
        "        h = self.end_conv(h)\n",
        "        assert list(h.size()) == [x.size(0), self.output_channels, x.size(2), x.size(3)]\n",
        "        return h\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import WandbLogger"
      ],
      "metadata": {
        "id": "KFjPmFYpXHcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMyupC46t836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "35c0e062-6f4e-47db-a8d4-a441a8fb500b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msdm8499\u001b[0m (\u001b[33msdm8499pro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>./wandb/run-20230415_173217-icuojblr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sdm8499pro/MNIST/runs/icuojblr' target=\"_blank\">comic-monkey-19</a></strong> to <a href='https://wandb.ai/sdm8499pro/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sdm8499pro/MNIST' target=\"_blank\">https://wandb.ai/sdm8499pro/MNIST</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sdm8499pro/MNIST/runs/icuojblr' target=\"_blank\">https://wandb.ai/sdm8499pro/MNIST/runs/icuojblr</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb_logger = WandbLogger(project='MNIST', log_model='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "260ea88e95614cc7b356cfdc93792ee2",
            "6496c601c0ec4bd1aa3c339648f0e475",
            "bd439d3609f04974962c7d622741088a",
            "2f56cd8e34704eefab1bf18050434f9e",
            "706c2ecf7ccc4bddb3a01449924bbeae",
            "d859ad05802246399bae5dd5fe6dc944",
            "ad3b9ee0fc9d4a82ae15c7f5f88354b8",
            "7431bb9dc4104033bc56e53ffdbf1e0e",
            "753834e1ae9f455696ae5184daf6a77a",
            "500020f9a6e54fdfbc0947f16052e793",
            "b66742dc46a74fa2a2de740a0d8b77eb",
            "f9a7651ba96b4cf0ba46da4eea500f2e",
            "44f4d689ee494fb7aaf654524d0ea539",
            "86f8e4e4d28e4e349e21b3396d5fbbc0",
            "df88bfd1064d488e8d1cc49787fb46d6",
            "48412fa7baa44e6684f94f9ded40337d",
            "d9ac554377a44be8941395d2f7f1ee5a",
            "9ed05c6521454fa395b1c45dc6f298c9",
            "8ef95aee14f6491eb4cf077177064b7d",
            "b0e758919ae94e8daed5bfd852c05f72",
            "7ebef48c080244f0a297b22d3d41e270",
            "d5f5a567915d417bb8a9daa9c70e3689"
          ]
        },
        "id": "luomGPKgj9rt",
        "outputId": "7df6c40c-4149-4df4-d3af-d517fb93a9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type                  | Params\n",
            "------------------------------------------------\n",
            "0 | model | UNet                  | 1.5 M \n",
            "1 | sde   | VariancePreservingSDE | 1     \n",
            "------------------------------------------------\n",
            "1.5 M     Trainable params\n",
            "1         Non-trainable params\n",
            "1.5 M     Total params\n",
            "6.157     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "260ea88e95614cc7b356cfdc93792ee2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94\n",
            "Number of function evaluations: 14\n",
            "tensor(601.6431, device='cuda:0', dtype=torch.float64) tensor(64)\n",
            "avg_bpd tensor(9.4007, device='cuda:0', dtype=torch.float64)\n",
            "1781\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9a7651ba96b4cf0ba46da4eea500f2e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "#from model import UNet\n",
        "#from diffusion import VariancePreservingSDE, ode_sampler , ode_likelihood\n",
        "#import dataset as dataset\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class obj(object):\n",
        "    def __init__(self, d):\n",
        "        for a, b in d.items():\n",
        "            if isinstance(b, (list, tuple)):\n",
        "               setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])\n",
        "            else:\n",
        "               setattr(self, a, obj(b) if isinstance(b, dict) else b)\n",
        "\n",
        "class ScoreBasedDiffusion(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, conf):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conf  = conf\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.validation_step_outputs = []\n",
        "        self.test_step_outputs = []\n",
        "        self.training_step_outputs =[]\n",
        "\n",
        "        self.model = UNet(input_channels= self.conf.model.in_channel,\n",
        "                          input_height=self.conf.model.height,\n",
        "                          ch= self.conf.model.ch,\n",
        "                          ch_mult=self.conf.model.channel_multiplier,\n",
        "                          num_res_blocks=self.conf.model.n_res_blocks,\n",
        "                          attn_resolutions= (16,),\n",
        "                          resamp_with_conv=True,\n",
        "                          dropout=self.conf.model.dropout,\n",
        "                          )\n",
        "\n",
        "        T1 = torch.nn.Parameter(torch.FloatTensor([self.conf.model.sde.T]), requires_grad=False)\n",
        "        \n",
        "        self.sde = VariancePreservingSDE(beta_min=0.1, beta_max=20.0, T=T1)\n",
        "\n",
        "    def forward(self , x, t):\n",
        "        score = self.model(x , t)\n",
        "        return score\n",
        "\n",
        "    def setup(self, stage):\n",
        "        self.train_set, self.valid_set , self.test_set = get_train_data(self.conf)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        if self.conf.training.optimizer.type == 'adam':\n",
        "            optimizer = optim.Adam(self.model.parameters(), lr=self.conf.training.optimizer.lr)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "\n",
        "        eps = 1e-5\n",
        "\n",
        "        x , _ = batch\n",
        "\n",
        "        random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
        "        z = torch.randn_like(x)\n",
        "        std = self.sde.marginal_prob_std(random_t)\n",
        "        perturbed_x = x + z * std[:, None, None, None]\n",
        "        score = self.model(perturbed_x, random_t)\n",
        "        loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "        tensorboard_logs = {'train_loss': loss}\n",
        "        self.log('train_loss', loss)\n",
        "\n",
        "        \n",
        "        #x = (x * 255. + torch.rand_like(x)) / 256.    \n",
        "        #_, bpd = ode_likelihood(x, self.model, x.shape[0], eps)\n",
        "\n",
        "        self.training_step_outputs.append({'train_loss': loss})# , 'bpd': bpd.sum() , 'bpd_items': bpd.shape[0]})\n",
        "\n",
        "        return {'loss': loss, 'log': tensorboard_logs}\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "      avg_loss         = torch.stack([x['train_loss'] for x in self.training_step_outputs]).mean()   \n",
        "      #all_bpd =torch.stack([x['bpd'] for x in self.training_step_outputs]).sum()\n",
        "\n",
        "      #all_items = torch.stack([torch.tensor(x['bpd_items']) for x in self.training_step_outputs]).sum()\n",
        "      self.log('avg_train_loss', avg_loss)\n",
        "      #wandb.log('avg_bpd', all_bpd/all_items)\n",
        "      \n",
        "      return {'avg_train_loss': avg_loss}\n",
        "    \n",
        "\n",
        "    def train_dataloader(self):\n",
        "\n",
        "        train_loader = DataLoader(self.train_set,\n",
        "                                batch_size=self.conf.training.dataloader.batch_size,\n",
        "                                shuffle=True,\n",
        "                                num_workers=self.conf.training.dataloader.num_workers,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=self.conf.training.dataloader.drop_last)\n",
        "        \n",
        "        print(len(train_loader))\n",
        "\n",
        "        return train_loader\n",
        "\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        valid_loader = DataLoader(self.valid_set,\n",
        "                                  batch_size=self.conf.validation.dataloader.batch_size,\n",
        "                                  shuffle=False,\n",
        "                                  num_workers=self.conf.validation.dataloader.num_workers,\n",
        "                                  pin_memory=True,\n",
        "                                  drop_last=self.conf.validation.dataloader.drop_last)\n",
        "\n",
        "        print(len(valid_loader))\n",
        "        return valid_loader\n",
        "    \n",
        "    def test_dataloader(self):\n",
        "\n",
        "        test_loader = DataLoader(self.test_set,\n",
        "                                batch_size=self.conf.test.dataloader.batch_size,\n",
        "                                shuffle=False,\n",
        "                                num_workers=self.conf.test.dataloader.num_workers,\n",
        "                                pin_memory=True,\n",
        "                                drop_last=self.conf.test.dataloader.drop_last)\n",
        "        \n",
        "        return test_loader\n",
        "\n",
        "    \n",
        "    def validation_step(self, batch, batch_nb):\n",
        "\n",
        "        eps = 1e-5\n",
        "        x , _ = batch\n",
        "\n",
        "        random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
        "        z = torch.randn_like(x)\n",
        "        std = self.sde.marginal_prob_std(random_t)\n",
        "        perturbed_x = x + z * std[:, None, None, None]\n",
        "        score = self.model(perturbed_x, random_t)\n",
        "        loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
        "\n",
        "        x = (x * 255. + torch.rand_like(x)) / 256.    \n",
        "        _, bpd = ode_likelihood(x, self.model, x.shape[0], eps)\n",
        "    \n",
        "        #all_bpds += bpd.sum()\n",
        "        #all_items += bpd.shape[0]\n",
        "\n",
        "        #avg_bpd = bpd.sum() / bpd.shape[0]\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "        self.validation_step_outputs.append({'val_loss': loss , 'bpd': bpd.sum() , 'bpd_items': bpd.shape[0]})\n",
        "    \n",
        "        return {'val_loss': loss}\n",
        "    \n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        avg_loss         = torch.stack([x['val_loss'] for x in self.validation_step_outputs]).mean()\n",
        "        \n",
        "        all_bpd =torch.stack([x['bpd'] for x in self.validation_step_outputs]).sum()\n",
        "\n",
        "        all_items = torch.stack([torch.tensor(x['bpd_items']) for x in self.validation_step_outputs]).sum()\n",
        "\n",
        "        #tensorboard_logs = {'val_loss': avg_loss , 'avg_bpd': all_bpd/all_items}\n",
        "\n",
        "        sample_batch_size = 64\n",
        "\n",
        "        samples = ode_sampler(self.model, sample_batch_size)\n",
        "\n",
        "        samples = samples.clamp(0.0, 1.0)\n",
        "\n",
        "        sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
        "        wandb.log({'val_images': [wandb.Image(sample_grid, caption='MNIST')]})\n",
        "        wandb.log({'avg_bpd': all_bpd/all_items})\n",
        "        self.log('avg_bpd', all_bpd/all_items)\n",
        "\n",
        "        print(all_bpd, all_items)\n",
        "        print('avg_bpd', all_bpd/all_items)\n",
        "\n",
        "        self.validation_step_outputs = []\n",
        "        \n",
        "        return {'val_loss': avg_loss , 'avg_bpd' :all_bpd/all_items}\n",
        "    \n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "\n",
        "        sample_batch_size = 64\n",
        "        samples = ode_sampler(self.model,\n",
        "                              sample_batch_size)\n",
        "\n",
        "        samples = samples.clamp(0.0, 1.0)\n",
        "\n",
        "        sample_grid = make_grid(samples, nrow=int(np.sqrt(sample_batch_size)))\n",
        "        #self.logger.experiment.add_image(f'generated_images', sample_grid, self.current_epoch)\n",
        "\n",
        "\n",
        "        x = (x * 255. + torch.rand_like(x)) / 256.    \n",
        "        _, bpd = ode_likelihood(x, self.model,\n",
        "                                x.shape[0], eps=1e-5)\n",
        "\n",
        "        self.log('testbpd', bpd)\n",
        "    \n",
        "        self.test_step_outputs.append({'bpd': bpd.sum() , 'bpd_items': bpd.shape[0]})\n",
        "\n",
        "        return {'bpd': bpd.sum() , 'bpd_items': bpd.shape[0]}\n",
        "\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "\n",
        "      all_bpd =torch.stack([x['bpd'] for x in self.test_step_outputs]).sum()\n",
        "      all_items = torch.stack([torch.tensor(x['bpd_items']) for x in self.test_step_outputs]).sum()\n",
        "      tensorboard_logs = {'test_avg_bpd': all_bpd/all_items}\n",
        "      self.log('test_avg_bpd', all_bpd/all_items)\n",
        "\n",
        "      return {'log': tensorboard_logs}\n",
        " \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    path_to_config = \"/content/mnist.json\"\n",
        "\n",
        "    with open(path_to_config, 'r') as f:\n",
        "        conf = json.load(f)\n",
        "\n",
        "    conf = obj(conf)\n",
        "\n",
        "    score_based_diffusion_model = ScoreBasedDiffusion(conf)\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(dirpath=os.path.join(\"/content/sample_data/ckptdir\"),\n",
        "                                           filename=\"best\",\n",
        "                                            monitor='avg_bpd',\n",
        "                                            mode = 'min', \n",
        "                                            verbose=False,\n",
        "                                            save_last=True,\n",
        "                                            save_top_k=1,\n",
        "                                            save_weights_only=True,\n",
        "                                            \n",
        "                                            )\n",
        "    \n",
        "    trainer = pl.Trainer(fast_dev_run= False,logger=wandb_logger, accelerator =\"gpu\",max_epochs= 25,num_nodes= 1,check_val_every_n_epoch=20 ,callbacks=checkpoint_callback)\n",
        "\n",
        "    trainer.fit(score_based_diffusion_model)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "ylPz9YTAkPD2",
        "outputId": "a8e8548d-a0db-4607-968f-2375c1da346c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a2bce46dc485>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
          ]
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "260ea88e95614cc7b356cfdc93792ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6496c601c0ec4bd1aa3c339648f0e475",
              "IPY_MODEL_bd439d3609f04974962c7d622741088a",
              "IPY_MODEL_2f56cd8e34704eefab1bf18050434f9e"
            ],
            "layout": "IPY_MODEL_706c2ecf7ccc4bddb3a01449924bbeae"
          }
        },
        "6496c601c0ec4bd1aa3c339648f0e475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d859ad05802246399bae5dd5fe6dc944",
            "placeholder": "​",
            "style": "IPY_MODEL_ad3b9ee0fc9d4a82ae15c7f5f88354b8",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "bd439d3609f04974962c7d622741088a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7431bb9dc4104033bc56e53ffdbf1e0e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_753834e1ae9f455696ae5184daf6a77a",
            "value": 2
          }
        },
        "2f56cd8e34704eefab1bf18050434f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500020f9a6e54fdfbc0947f16052e793",
            "placeholder": "​",
            "style": "IPY_MODEL_b66742dc46a74fa2a2de740a0d8b77eb",
            "value": " 2/2 [00:01&lt;00:00,  1.39it/s]"
          }
        },
        "706c2ecf7ccc4bddb3a01449924bbeae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d859ad05802246399bae5dd5fe6dc944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad3b9ee0fc9d4a82ae15c7f5f88354b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7431bb9dc4104033bc56e53ffdbf1e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753834e1ae9f455696ae5184daf6a77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "500020f9a6e54fdfbc0947f16052e793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b66742dc46a74fa2a2de740a0d8b77eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a7651ba96b4cf0ba46da4eea500f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f4d689ee494fb7aaf654524d0ea539",
              "IPY_MODEL_86f8e4e4d28e4e349e21b3396d5fbbc0",
              "IPY_MODEL_df88bfd1064d488e8d1cc49787fb46d6"
            ],
            "layout": "IPY_MODEL_48412fa7baa44e6684f94f9ded40337d"
          }
        },
        "44f4d689ee494fb7aaf654524d0ea539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9ac554377a44be8941395d2f7f1ee5a",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed05c6521454fa395b1c45dc6f298c9",
            "value": "Epoch 10: 100%"
          }
        },
        "86f8e4e4d28e4e349e21b3396d5fbbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef95aee14f6491eb4cf077177064b7d",
            "max": 1781,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0e758919ae94e8daed5bfd852c05f72",
            "value": 1781
          }
        },
        "df88bfd1064d488e8d1cc49787fb46d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ebef48c080244f0a297b22d3d41e270",
            "placeholder": "​",
            "style": "IPY_MODEL_d5f5a567915d417bb8a9daa9c70e3689",
            "value": " 1781/1781 [01:29&lt;00:00, 19.79it/s, v_num=jblr]"
          }
        },
        "48412fa7baa44e6684f94f9ded40337d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d9ac554377a44be8941395d2f7f1ee5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed05c6521454fa395b1c45dc6f298c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef95aee14f6491eb4cf077177064b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e758919ae94e8daed5bfd852c05f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ebef48c080244f0a297b22d3d41e270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f5a567915d417bb8a9daa9c70e3689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}